{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-27T20:22:39.626116Z","iopub.execute_input":"2022-03-27T20:22:39.626574Z","iopub.status.idle":"2022-03-27T20:22:48.258201Z","shell.execute_reply.started":"2022-03-27T20:22:39.626443Z","shell.execute_reply":"2022-03-27T20:22:48.257437Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-03-27T20:22:48.260193Z","iopub.execute_input":"2022-03-27T20:22:48.260471Z","iopub.status.idle":"2022-03-27T20:22:48.720982Z","shell.execute_reply.started":"2022-03-27T20:22:48.260433Z","shell.execute_reply":"2022-03-27T20:22:48.720238Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Hyper Parameters \nnum_classes = 400\nnum_epochs = 5\nbatch_size = 16\nlearning_rate = 0.01","metadata":{"execution":{"iopub.status.busy":"2022-03-27T20:22:48.722494Z","iopub.execute_input":"2022-03-27T20:22:48.722754Z","iopub.status.idle":"2022-03-27T20:22:48.728918Z","shell.execute_reply.started":"2022-03-27T20:22:48.722716Z","shell.execute_reply":"2022-03-27T20:22:48.728132Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\ndirectories = ['../input/csc4851-homework4/birds_400/test',\n                                '../input/csc4851-homework4/birds_400/train',\n                                '../input//csc4851-homework4/birds_400/valid']\n\nfor dir in directories:\n    label = []\n    path = []\n    for dirname, _,filenames in os.walk(dir):\n        for filename in filenames:\n            label.append(os.path.split(dirname)[1])\n            path.append(os.path.join(dirname,filename))\n    if dir == directories[0]:\n        df_test = pd.DataFrame(columns=['path','label'])\n        df_test['path']=path\n        df_test['label']=label\n    elif dir == directories[1]:\n        df_train = pd.DataFrame(columns=['path','label'])\n        df_train['path']=path\n        df_train['label']=label        \n    elif dir == directories[2]:\n        df_valid = pd.DataFrame(columns=['path','label'])\n        df_valid['path']=path\n        df_valid['label']=label","metadata":{"execution":{"iopub.status.busy":"2022-03-27T20:22:48.731627Z","iopub.execute_input":"2022-03-27T20:22:48.732025Z","iopub.status.idle":"2022-03-27T20:22:48.748207Z","shell.execute_reply.started":"2022-03-27T20:22:48.731985Z","shell.execute_reply":"2022-03-27T20:22:48.747533Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"transform_dict = { 'train': transforms.Compose([\n        transforms.Resize(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ]),\n                  'valid': transforms.Compose([\n        transforms.Resize(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ]),\n                 }\ntest_dict = transforms.Compose([\n        transforms.Resize(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\nroot_path = '../input/birddata/birds_400/'\nimage_data = {x: dsets.ImageFolder(os.path.join(root_path,x),transform_dict[x]) for x in ['train','valid']}\ndata_loaders = {x: torch.utils.data.DataLoader(image_data[x], batch_size=batch_size, shuffle = True, drop_last= False, num_workers=2) for x in ['train','valid']}\ndataset_sizes = {x: len(image_data[x]) for x in ['train','valid']}\n\ntest_root_path = '../input/birddata/birds_400/test'\ntest_data = dsets.ImageFolder(root=test_root_path, transform=test_dict)\ntest_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle = True, drop_last=False, num_workers=2)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-03-27T20:22:48.749426Z","iopub.execute_input":"2022-03-27T20:22:48.750152Z","iopub.status.idle":"2022-03-27T20:22:49.669618Z","shell.execute_reply.started":"2022-03-27T20:22:48.750115Z","shell.execute_reply":"2022-03-27T20:22:49.668751Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib as plt\ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.pyplot.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pyplot.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(test_data_loader))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T20:22:49.670828Z","iopub.execute_input":"2022-03-27T20:22:49.671087Z","iopub.status.idle":"2022-03-27T20:22:50.320014Z","shell.execute_reply.started":"2022-03-27T20:22:49.671053Z","shell.execute_reply":"2022-03-27T20:22:50.319266Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\nresnet = models.resnet101(pretrained=True)\ncriterion = nn.CrossEntropyLoss()  \noptimizer = torch.optim.SGD(resnet.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T20:22:50.321533Z","iopub.execute_input":"2022-03-27T20:22:50.322032Z","iopub.status.idle":"2022-03-27T20:22:51.243348Z","shell.execute_reply.started":"2022-03-27T20:22:50.321992Z","shell.execute_reply":"2022-03-27T20:22:51.242627Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import time\nimport copy\n\ndef train_model(model,criteron,optimizer, scheduler, num_epochs=5):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        for phase in ['train','valid']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n            running_loss = 0.0\n            running_corrects = 0\n\n        \n            for inputs, labels in data_loaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                optimizer.zero_grad()\n                \n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                loss = criterion(outputs, labels)\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n        \n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n            epoch_loss = running_loss/dataset_sizes[phase]\n            epoch_acc = running_corrects/dataset_sizes[phase]\n            \n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            if phase == 'valid' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best val Acc: {best_acc:4f}')\n\n\n    model.load_state_dict(best_model_wts)\n    return model        ","metadata":{"execution":{"iopub.status.busy":"2022-03-27T20:22:51.244676Z","iopub.execute_input":"2022-03-27T20:22:51.244963Z","iopub.status.idle":"2022-03-27T20:22:51.385089Z","shell.execute_reply.started":"2022-03-27T20:22:51.244925Z","shell.execute_reply":"2022-03-27T20:22:51.384305Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"resnet = models.resnet101(pretrained=True)\nfor param in resnet.parameters():\n    param.requires_grad = False\n    \nnum_ftrs = resnet.fc.in_features\nresnet.fc = torch.nn.Linear(num_ftrs, num_classes)\nresnet = resnet.to(device)\ncriterion = nn.CrossEntropyLoss()  \noptimizer = torch.optim.SGD(resnet.fc.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T20:22:51.386486Z","iopub.execute_input":"2022-03-27T20:22:51.386854Z","iopub.status.idle":"2022-03-27T20:22:54.155481Z","shell.execute_reply.started":"2022-03-27T20:22:51.386777Z","shell.execute_reply":"2022-03-27T20:22:54.154640Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model_fit = train_model(resnet,criterion,optimizer,scheduler,num_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T20:22:54.158334Z","iopub.execute_input":"2022-03-27T20:22:54.158624Z","iopub.status.idle":"2022-03-27T20:40:27.108599Z","shell.execute_reply.started":"2022-03-27T20:22:54.158570Z","shell.execute_reply":"2022-03-27T20:40:27.107766Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Test the Model\nimport torch.nn.functional as F\nrunning_corrects = 0\nrunning_loss = 0\nfor inputs, labels in test_data_loader:\n    inputs = inputs.to(device)\n    labels = labels.to(device)\n    outputs = model_fit(inputs)\n    _, preds = torch.max(outputs, 1)\n    loss = criterion(outputs, labels)\n    running_loss += loss.item() * inputs.size(0)\n    running_corrects += torch.sum(preds == labels.data)\n    probs = F.softmax(outputs,1)\nepoch_loss = running_loss/len(test_data)\nepoch_acc = running_corrects/len(test_data)\n    \nprint('Accuracy of the model on the 2000 test images: %d %%' % (100 * epoch_acc))","metadata":{"execution":{"iopub.status.busy":"2022-03-27T21:24:52.695488Z","iopub.execute_input":"2022-03-27T21:24:52.696255Z","iopub.status.idle":"2022-03-27T21:24:59.464874Z","shell.execute_reply.started":"2022-03-27T21:24:52.696202Z","shell.execute_reply":"2022-03-27T21:24:59.464006Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"log,logloss = [], []\nfor i in range(400):\n    log= -torch.log((1/16)*torch.sum((probs[:,i])))\n    logloss.append(log)\nlogloss = torch.FloatTensor(logloss)\nlogloss","metadata":{"execution":{"iopub.status.busy":"2022-03-27T22:04:33.635491Z","iopub.execute_input":"2022-03-27T22:04:33.636056Z","iopub.status.idle":"2022-03-27T22:04:33.678085Z","shell.execute_reply.started":"2022-03-27T22:04:33.636015Z","shell.execute_reply":"2022-03-27T22:04:33.677278Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"Id = np.arange(400)\nmy_submission = pd.DataFrame({'Id': Id, 'birds': logloss})\nmy_submission.to_csv('Daniel_submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T22:09:37.604037Z","iopub.execute_input":"2022-03-27T22:09:37.604300Z","iopub.status.idle":"2022-03-27T22:09:37.613635Z","shell.execute_reply.started":"2022-03-27T22:09:37.604269Z","shell.execute_reply":"2022-03-27T22:09:37.612888Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache() ","metadata":{"execution":{"iopub.status.busy":"2022-03-27T20:40:27.507157Z","iopub.status.idle":"2022-03-27T20:40:27.507715Z","shell.execute_reply.started":"2022-03-27T20:40:27.507483Z","shell.execute_reply":"2022-03-27T20:40:27.507509Z"},"trusted":true},"execution_count":null,"outputs":[]}]}