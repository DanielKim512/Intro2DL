{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-28T16:11:33.596606Z","iopub.execute_input":"2022-03-28T16:11:33.597169Z","iopub.status.idle":"2022-03-28T16:11:42.174117Z","shell.execute_reply.started":"2022-03-28T16:11:33.597126Z","shell.execute_reply":"2022-03-28T16:11:42.173530Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:11:42.175521Z","iopub.execute_input":"2022-03-28T16:11:42.175864Z","iopub.status.idle":"2022-03-28T16:11:42.191469Z","shell.execute_reply.started":"2022-03-28T16:11:42.175825Z","shell.execute_reply":"2022-03-28T16:11:42.190650Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Hyper Parameters \nnum_classes = 400\nnum_epochs = 5\nbatch_size = 16\nlearning_rate = 0.01","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:11:42.192647Z","iopub.execute_input":"2022-03-28T16:11:42.193098Z","iopub.status.idle":"2022-03-28T16:11:42.214855Z","shell.execute_reply.started":"2022-03-28T16:11:42.193052Z","shell.execute_reply":"2022-03-28T16:11:42.214205Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"transform_dict = { 'train': transforms.Compose([\n        transforms.Resize(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ]),\n                  'valid': transforms.Compose([\n        transforms.Resize(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ]),\n                 }\ntest_dict = transforms.Compose([\n        transforms.Resize(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\nroot_path = '../input/birddata/birds_400/'\nimage_data = {x: dsets.ImageFolder(os.path.join(root_path,x),transform_dict[x]) for x in ['train','valid']}\ndata_loaders = {x: torch.utils.data.DataLoader(image_data[x], batch_size=batch_size, shuffle = True, drop_last= False, num_workers=2) for x in ['train','valid']}\ndataset_sizes = {x: len(image_data[x]) for x in ['train','valid']}\n\ntest_root_path = '../input/birddata/birds_400/test'\ntest_data = dsets.ImageFolder(root=test_root_path, transform=test_dict)\ntest_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle = True, drop_last=False, num_workers=2)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:11:42.216907Z","iopub.execute_input":"2022-03-28T16:11:42.217500Z","iopub.status.idle":"2022-03-28T16:11:43.181411Z","shell.execute_reply.started":"2022-03-28T16:11:42.217461Z","shell.execute_reply":"2022-03-28T16:11:43.180598Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib as plt\ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.pyplot.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pyplot.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(test_data_loader))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:11:43.182617Z","iopub.execute_input":"2022-03-28T16:11:43.183005Z","iopub.status.idle":"2022-03-28T16:11:43.904151Z","shell.execute_reply.started":"2022-03-28T16:11:43.182968Z","shell.execute_reply":"2022-03-28T16:11:43.903449Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\nresnet = models.resnet101(pretrained=True)\ncriterion = nn.CrossEntropyLoss()  \noptimizer = torch.optim.SGD(resnet.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:11:43.905850Z","iopub.execute_input":"2022-03-28T16:11:43.906140Z","iopub.status.idle":"2022-03-28T16:11:44.889816Z","shell.execute_reply.started":"2022-03-28T16:11:43.906103Z","shell.execute_reply":"2022-03-28T16:11:44.889044Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import time\nimport copy\n\ndef train_model(model,criteron,optimizer, scheduler, num_epochs=5):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        for phase in ['train','valid']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n            running_loss = 0.0\n            running_corrects = 0\n\n        \n            for inputs, labels in data_loaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                optimizer.zero_grad()\n                \n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                loss = criterion(outputs, labels)\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n        \n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n            epoch_loss = running_loss/dataset_sizes[phase]\n            epoch_acc = running_corrects/dataset_sizes[phase]\n            \n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            if phase == 'valid' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best val Acc: {best_acc:4f}')\n\n\n    model.load_state_dict(best_model_wts)\n    return model        ","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:11:44.891047Z","iopub.execute_input":"2022-03-28T16:11:44.891470Z","iopub.status.idle":"2022-03-28T16:11:44.904641Z","shell.execute_reply.started":"2022-03-28T16:11:44.891433Z","shell.execute_reply":"2022-03-28T16:11:44.903723Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"resnet = models.resnet101(pretrained=True)\nfor param in resnet.parameters():\n    param.requires_grad = False\n    \nnum_ftrs = resnet.fc.in_features\nresnet.fc = torch.nn.Linear(num_ftrs, num_classes)\nresnet = resnet.to(device)\ncriterion = nn.CrossEntropyLoss()  \noptimizer = torch.optim.SGD(resnet.fc.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:11:44.905956Z","iopub.execute_input":"2022-03-28T16:11:44.906280Z","iopub.status.idle":"2022-03-28T16:11:47.780033Z","shell.execute_reply.started":"2022-03-28T16:11:44.906241Z","shell.execute_reply":"2022-03-28T16:11:47.779186Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model_fit = train_model(resnet,criterion,optimizer,scheduler,num_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:11:47.785915Z","iopub.execute_input":"2022-03-28T16:11:47.788574Z","iopub.status.idle":"2022-03-28T16:29:04.346819Z","shell.execute_reply.started":"2022-03-28T16:11:47.788534Z","shell.execute_reply":"2022-03-28T16:29:04.345041Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Test the Model\nimport torch.nn.functional as F\nrunning_corrects = 0\nrunning_loss = 0\nfor inputs, labels in test_data_loader:\n    inputs = inputs.to(device)\n    labels = labels.to(device)\n    outputs = model_fit(inputs)\n    _, preds = torch.max(outputs, 1)\n    loss = criterion(outputs, labels)\n    running_loss += loss.item() * inputs.size(0)\n    running_corrects += torch.sum(preds == labels.data)\n    probs = F.softmax(outputs,1)\nepoch_loss = running_loss/len(test_data)\nepoch_acc = running_corrects/len(test_data)\n    \nprint('Accuracy of the model on the 2000 test images: %d %%' % (100 * epoch_acc))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:29:04.350213Z","iopub.execute_input":"2022-03-28T16:29:04.350700Z","iopub.status.idle":"2022-03-28T16:29:13.486824Z","shell.execute_reply.started":"2022-03-28T16:29:04.350656Z","shell.execute_reply":"2022-03-28T16:29:13.485237Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"zero_test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=5, shuffle = False, drop_last=False, num_workers=2)\nfor zinputs, zlabels in zero_test_data_loader:\n    zinputs = zinputs.to(device)\n    zlabels = zlabels.to(device)\n    zoutputs = model_fit(zinputs)\n    _, zpreds = torch.max(zoutputs, 1)\n    zloss = criterion(zoutputs, zlabels)\n    zprobs = F.softmax(zoutputs,1)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:29:13.488456Z","iopub.execute_input":"2022-03-28T16:29:13.489053Z","iopub.status.idle":"2022-03-28T16:29:23.909512Z","shell.execute_reply.started":"2022-03-28T16:29:13.489012Z","shell.execute_reply":"2022-03-28T16:29:23.908527Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#Confirming that for label 399, log loss is 0.9348\nzloss","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:41:11.898731Z","iopub.execute_input":"2022-03-28T16:41:11.899008Z","iopub.status.idle":"2022-03-28T16:41:11.906012Z","shell.execute_reply.started":"2022-03-28T16:41:11.898977Z","shell.execute_reply":"2022-03-28T16:41:11.905183Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import itertools\nlog_loss = []\nfor i in range(1):\n    sample = (i*5)+1\n    k = int(np.floor(sample/5))\n    for my_input,my_label in itertools.islice(zero_test_data_loader,k,None):\n        my_input = my_input.to(device)\n        my_label = my_label.to(device)\n        my_outputs = model_fit(my_input)\n        _,mypreds = torch.max(my_outputs,1)\n        my_loss = criterion(my_outputs,my_label)\n        log_loss.append(my_loss)\nlog_loss","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:43:47.479458Z","iopub.execute_input":"2022-03-28T16:43:47.480167Z","iopub.status.idle":"2022-03-28T16:43:57.219076Z","shell.execute_reply.started":"2022-03-28T16:43:47.480127Z","shell.execute_reply":"2022-03-28T16:43:57.218351Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"log_loss = torch.FloatTensor(log_loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:45:21.263988Z","iopub.execute_input":"2022-03-28T16:45:21.264248Z","iopub.status.idle":"2022-03-28T16:45:21.275717Z","shell.execute_reply.started":"2022-03-28T16:45:21.264218Z","shell.execute_reply":"2022-03-28T16:45:21.275041Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"Id = np.arange(400)\nmy_submission = pd.DataFrame({'Id': Id, 'birds': log_loss})\nmy_submission.to_csv('Daniel_submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:45:26.532066Z","iopub.execute_input":"2022-03-28T16:45:26.532317Z","iopub.status.idle":"2022-03-28T16:45:26.540548Z","shell.execute_reply.started":"2022-03-28T16:45:26.532288Z","shell.execute_reply":"2022-03-28T16:45:26.539857Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache() ","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:29:28.273972Z","iopub.status.idle":"2022-03-28T16:29:28.274532Z","shell.execute_reply.started":"2022-03-28T16:29:28.274279Z","shell.execute_reply":"2022-03-28T16:29:28.274306Z"},"trusted":true},"execution_count":null,"outputs":[]}]}